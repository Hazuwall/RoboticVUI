{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filesystem\n",
    "import h5py\n",
    "\n",
    "def file_len(file):\n",
    "    for i, l in enumerate(file):\n",
    "        pass\n",
    "    file.seek(0, 0)\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dataset(old_storage_path, old_label, new_storage_path, new_label):\n",
    "    with h5py.File(old_storage_path, 'r') as f1:\n",
    "        with h5py.File(new_storage_path, 'a') as f2:\n",
    "            f2[new_label] = f1[old_label]\n",
    "\n",
    "copy_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw(data_folder_path, shuffle=False, label=\"\"):\n",
    "    \"\"\"Save all audiofiles in the given folder as dataset.\n",
    "    The length of data is the count of frames to save from each file.\"\"\"\n",
    "    new_path = filesystem.get_dataset_path('r')\n",
    "    with h5py.File(new_path, 'a') as f:\n",
    "        file_list = os.listdir(data_folder_path)\n",
    "        if shuffle:\n",
    "            random.shuffle(file_list)\n",
    "        length = len(file_list)\n",
    "        data_length = 24000\n",
    "        dset = f.create_dataset(\"raw/\" + label, dtype=\"float32\",\n",
    "                                shape=(length, data_length),\n",
    "                                compression=\"lzf\")\n",
    "        index = 0\n",
    "        with open(new_path + '.txt', 'w') as indexer:\n",
    "            for filename in file_list:\n",
    "                file_path = os.path.join(data_folder_path, filename)\n",
    "                data = p.read(file_path)\n",
    "                if len(data) > data_length:\n",
    "                    dset[index, :] = data[0:data_length]\n",
    "                else:\n",
    "                    dset[index, 0:len(data)] = data\n",
    "                if (index+1) % 100 == 0:\n",
    "                    print(str(index+1)+\"/\"+str(length))\n",
    "                indexer.write(filename + '\\n')\n",
    "                index += 1\n",
    "        print(str(length)+\"/\"+str(length))\n",
    "\n",
    "save_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mix():\n",
    "    new_path = filesystem.get_dataset_path('r')\n",
    "    dsets = {}\n",
    "    with open(cfg.datasets_root + \"mix.txt\", 'r') as f:\n",
    "        length = (file_len(f)+1)//4\n",
    "        with h5py.File(new_path, 'a') as dset_file:\n",
    "            dset_mix = dset_file.create_dataset(\"raw/\", dtype=\"float32\",\n",
    "                                                shape=(\n",
    "                                                    length*2, cfg.framerate),\n",
    "                                                compression=\"lzf\")\n",
    "            dset_index = 0\n",
    "            try:\n",
    "                for i, line in enumerate(f):\n",
    "                    if (i % 4 == 0) or (i % 4 == 3):\n",
    "                        continue\n",
    "                    path, index = line.split(',')\n",
    "                    path = cfg.datasets_root + path\n",
    "                    index = int(index)\n",
    "\n",
    "                    if not (path in dsets):\n",
    "                        dsets[path] = h5py.File(path, 'r')\n",
    "                    dset_mix[dset_index] = dsets[path]['raw'][index,\n",
    "                                                              :cfg.framerate]\n",
    "                    dset_index += 1\n",
    "\n",
    "                    if (dset_index+1) % 100 == 0:\n",
    "                        print(str(dset_index+1)+\"/\"+str(length*2))\n",
    "                print(str(length*2)+\"/\"+str(length*2))\n",
    "            finally:\n",
    "                for _, dset in dsets.items():\n",
    "                    dset.close()\n",
    "\n",
    "save_mix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dynamic_time_raw(storage_path, folder_path, time_list, framerate):\n",
    "    \"\"\"Save all audiofiles in subfolders as datasets.\n",
    "    A name of the subfolder is a duration in seconds and label of the appropriate dataset.\"\"\"\n",
    "    for t in time_list:\n",
    "        save_raw(storage_path, os.path.join(\n",
    "            folder_path, str(t)), framerate * t, label=str(t))\n",
    "\n",
    "save_dynamic_time_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dynamic_time_raw(old_storage_path, new_storage_path, time_list, framerate):\n",
    "    \"\"\"Join datasets of raw audio grouped by time to one dataset of one-second audio.\"\"\"\n",
    "    with h5py.File(old_storage_path, 'r') as f1:\n",
    "        with h5py.File(new_storage_path, 'a') as f2:\n",
    "            length = 0\n",
    "            for t in time_list:\n",
    "                length += len(f1[\"raw/\" + str(t)])*t\n",
    "            dset2 = f2.create_dataset(\"raw\", dtype=\"float32\",\n",
    "                                      shape=(length, framerate), maxshape=(\n",
    "                                          None, framerate),\n",
    "                                      compression=\"lzf\")\n",
    "            start = 0\n",
    "            for t in time_list:\n",
    "                dset1 = f1[\"raw/\" + str(t)]\n",
    "                end = start+(len(dset1)*t)\n",
    "                dset2[start:end] = np.reshape(dset1, (-1, framerate))\n",
    "                start = end\n",
    "                print(t)\n",
    "\n",
    "join_dynamic_time_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_harmonics(label=\"\"):\n",
    "    old_path = cfg.get_dataset_path('r')\n",
    "    new_path = cfg.get_dataset_path('h')\n",
    "    with h5py.File(old_path, 'r') as f1:\n",
    "        with h5py.File(new_path, 'a') as f2:\n",
    "            dset1 = f1[\"raw/\" + label]\n",
    "            length = len(dset1)\n",
    "            dset2 = f2.create_dataset(\"harmonics/\" + label, dtype=\"float32\",\n",
    "                                      shape=(\n",
    "                                          length, cfg.preprocess_shape[0], cfg.preprocess_shape[1]),\n",
    "                                      compression=\"lzf\")\n",
    "            for i in range(length):\n",
    "                dset2[i, :, :] = sp.complete_preprocess(\n",
    "                    dset1[i, :cfg.framerate])\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(str(i+1)+\"/\"+str(length))\n",
    "            print(str(length)+\"/\"+str(length))\n",
    "\n",
    "save_harmonics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(label=\"\"):\n",
    "    old_path = filesystem.get_dataset_path('h')\n",
    "    new_path = filesystem.get_dataset_path('e')\n",
    "    with h5py.File(old_path, 'r') as f1:\n",
    "        with h5py.File(new_path, 'a') as f2:\n",
    "            dset1 = f1[\"harmonics/\" + label]\n",
    "            length = len(dset1)\n",
    "            dset2 = f2.create_dataset(\"embeddings/\" + label, dtype=\"float32\",\n",
    "                                      shape=(\n",
    "                                          length, cfg.embedding_shape[0], cfg.embedding_shape[1]),\n",
    "                                      compression=\"lzf\")\n",
    "            index = 0\n",
    "            while index+500 < length:\n",
    "                dset2[index:index+500, :,\n",
    "                      :] = sp.encode(dset1[index:index+500, :, :])\n",
    "                index += 500\n",
    "                print(str(index)+\"/\"+str(length))\n",
    "            if index != (length - 1):\n",
    "                dset2[index:, :, :] = sp.encode(dset1[index:, :, :])\n",
    "                print(str(length)+\"/\"+str(length))\n",
    "\n",
    "save_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patches(label=\"\"):\n",
    "    old_path = filesystem.get_dataset_path('e')\n",
    "    new_path = filesystem.get_dataset_path('p')\n",
    "    with h5py.File(old_path, 'r') as f1:\n",
    "        with h5py.File(new_path, 'a') as f2:\n",
    "            dset1 = f1[\"embeddings/\" + label]\n",
    "            length = len(dset1) * cfg.embedding_shape[0]\n",
    "            dset2 = f2.create_dataset(\"patches/\" + label, dtype=\"float32\",\n",
    "                                      shape=(\n",
    "                                          length, cfg.embedding_shape[1]*cfg.embedding_overlap),\n",
    "                                      compression=\"lzf\")\n",
    "            old_index = 0\n",
    "            old_step = 100\n",
    "            new_index = 0\n",
    "            new_step = old_step*cfg.embedding_shape[0]\n",
    "            while new_index+new_step < length:\n",
    "                dset2[new_index:new_index +\n",
    "                      new_step] = sp.extract_patches(dset1[old_index:old_index+old_step])\n",
    "                old_index += old_step\n",
    "                new_index += new_step\n",
    "                print(str(new_index)+\"/\"+str(length))\n",
    "            if new_index != (length - 1):\n",
    "                dset2[new_index:] = sp.extract_patches(dset1[old_index:])\n",
    "                print(str(length)+\"/\"+str(length))\n",
    "\n",
    "save_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}